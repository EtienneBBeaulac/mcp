{
    "id": "systematic-bug-investigation-with-loops",
    "name": "Systematic Bug Investigation Workflow",
    "version": "1.0.0",
    "description": "A comprehensive workflow for systematic bug and failing test investigation that prevents LLMs from jumping to conclusions. Enforces thorough evidence gathering, hypothesis formation, debugging instrumentation, and validation to achieve near 100% certainty about root causes. This workflow does NOT fix bugs - it produces detailed diagnostic writeups that enable effective fixing by providing complete understanding of what is happening, why it's happening, and supporting evidence.",
    "clarificationPrompts": [
        "What type of system is this? (web app, mobile app, backend service, desktop app, etc.)",
        "How consistently can you reproduce this bug? (always reproducible, sometimes reproducible, rarely reproducible)",
        "What was the last known working version or state if applicable?",
        "Are there any time constraints or urgency factors for this investigation?",
        "What level of system access do you have? (full codebase, limited access, production logs only)",
        "Do you have preferences for handling large log volumes? (sub-chat analysis, inline summaries only, or no preference for automatic decision)"
    ],
    "preconditions": [
        "User has identified a specific bug or failing test to investigate",
        "Agent has access to codebase analysis tools (grep, file readers, etc.)",
        "Agent has access to build/test execution tools for the project type",
        "User can provide error messages, stack traces, or test failure output",
        "Bug is reproducible with specific steps or a minimal test case"
    ],
    "metaGuidance": [
        "INVESTIGATION DISCIPLINE: Never propose fixes or solutions until Phase 6 (Comprehensive Diagnostic Writeup). Focus entirely on systematic evidence gathering and analysis.",
        "HYPOTHESIS RIGOR: All hypotheses must be based on concrete evidence from code analysis with quantified scoring (1-10 scales). Maximum 5 hypotheses per investigation.",
        "DEBUGGING INSTRUMENTATION: Always implement debugging mechanisms before running tests - logs, print statements, or test modifications that will provide evidence.",
        "EVIDENCE THRESHOLD: Require minimum 3 independent sources of evidence before confirming any hypothesis. Use objective verification criteria.",
        "SYSTEMATIC PROGRESSION: Complete each investigation phase fully before proceeding. Each phase builds critical context for the next with structured documentation.",
        "CONFIDENCE CALIBRATION: Use mathematical confidence framework with 9.0/10 minimum threshold. Actively challenge conclusions with adversarial analysis.",
        "UNCERTAINTY ACKNOWLEDGMENT: Explicitly document all remaining unknowns and their potential impact. No subjective confidence assessments.",
        "THOROUGHNESS: For complex bugs, recursively analyze dependencies and internals of identified components to ensure full picture.",
        "TEST INTEGRATION: Leverage existing tests to validate hypotheses where possible.",
        "LOG ENHANCEMENTS: Include class/function names. For repetitive logs, implement deduplication by tracking counts ('x[count]') and grouping related sequential logs for readability. See Phase 3 for detailed implementation patterns and examples.",
        "LOG ANALYSIS OFFLOADING: For voluminous logs (>500 lines), offload analysis to sub-chats with structured prompts. See Phase 4 for detailed sub-analysis implementation.",
        "RECURSION DEPTH: Limit recursive analysis to 3 levels deep to prevent analysis paralysis while ensuring thoroughness.",
        "INVESTIGATION BOUNDS: If investigation exceeds 20 steps or 4 hours without root cause, pause and reassess approach with user.",
        "AUTOMATION LEVELS: High=auto-approve >8.0 confidence decisions, Medium=standard confirmations, Low=extra confirmations for safety. Control workflow autonomy based on user preference.",
        "CONTEXT DOCUMENTATION: Maintain INVESTIGATION_CONTEXT.md throughout. Update after major milestones, failures, or user interventions to enable seamless handoffs between sessions.",
        "GIT FALLBACK STRATEGY: If git unavailable, gracefully skip commits/branches, log changes manually in CONTEXT.md with timestamps, warn user, document modifications for manual control.",
        "GIT ERROR HANDLING: Use run_terminal_cmd for git operations; if fails, output exact command for user manual execution. Never halt investigation due to git unavailability.",
        "TOOL AVAILABILITY AWARENESS: Check debugging tool availability before investigation design. Have fallbacks for when primary tools unavailable (grepâ†’file_search, etc).",
        "SECURITY PROTOCOLS: Sanitize sensitive data in logs/reproduction steps. Be mindful of exposing credentials, PII, or system internals during evidence collection phases.",
        "DYNAMIC RE-TRIAGE: Allow complexity upgrades during investigation if evidence reveals deeper issues. Safe downgrades only with explicit user confirmation after evidence review.",
        "DEVIL'S ADVOCATE REVIEW: Actively challenge primary hypothesis with available evidence. Seek alternative explanations and rate alternative likelihood before final confidence assessment.",
        "COLLABORATIVE HANDOFFS: Structure documentation for peer review and team coordination. Include methodology, reasoning, and complete evidence chain for knowledge transfer.",
        "FAILURE BOUNDS: Track investigation progress. If >20 steps or >4 hours without breakthrough, pause for user guidance. Document dead ends to prevent redundant work in future sessions.",
        "COGNITIVE BREAKS: After 10 investigation steps, pause and summarize progress to reset perspective.",
        "RUBBER DUCK: Verbalize hypotheses in sub-prompts to externalize reasoning and catch logical gaps.",
        "COLLABORATION READY: Document clearly for handoffs when stuck beyond iteration limits."
    ],
    "steps": [
        {
            "id": "phase-0-triage",
            "title": "Phase 0: Initial Triage & Context Gathering",
            "prompt": "**SYSTEMATIC INVESTIGATION BEGINS** - Your mission is to achieve near 100% certainty about this bug's root cause through systematic evidence gathering. NO FIXES will be proposed until Phase 6.\n\n**STEP 1: Bug Report Analysis**\nPlease provide the complete bug context:\n- **Bug Description**: What is the observed behavior vs expected behavior?\n- **Error Messages/Stack Traces**: Paste the complete error output\n- **Reproduction Steps**: How can this bug be consistently reproduced?\n- **Environment Details**: OS, language version, framework version, etc.\n- **Recent Changes**: Any recent commits, deployments, or configuration changes?\n\n**STEP 2: Project Type Classification**\nBased on the information provided, I will classify the project type and set debugging strategies:\n- **Languages/Frameworks**: Primary tech stack\n- **Build System**: Maven, Gradle, npm, etc.\n- **Testing Framework**: JUnit, Jest, pytest, etc.\n- **Logging System**: Available logging mechanisms\n- **Architecture**: Monolithic, microservices, distributed, serverless, etc.\n\n**STEP 3: Complexity Assessment**\nI will analyze the bug complexity using these criteria:\n- **Simple**: Single function/method, clear error path, minimal dependencies\n- **Standard**: Multiple components, moderate investigation required\n- **Complex**: Cross-system issues, race conditions, complex state management\n\n**OUTPUTS**: Set `projectType`, `bugComplexity`, `debuggingMechanism`, and `isDistributed` (true if architecture involves microservices/distributed systems) context variables.",
            "agentRole": "You are a senior debugging specialist and bug triage expert with 15+ years of experience across multiple technology stacks. Your expertise lies in quickly classifying bugs, understanding project architectures, and determining appropriate investigation strategies. You excel at extracting critical information from bug reports and setting up systematic investigation approaches.",
            "guidance": [
                "CLASSIFICATION ACCURACY: Proper complexity assessment determines investigation depth - be thorough but decisive",
                "CONTEXT CAPTURE: Gather complete environmental and situational context now to avoid gaps later",
                "DEBUGGING STRATEGY: Choose debugging mechanisms appropriate for the project type and bug complexity",
                "NO ASSUMPTIONS: If critical information is missing, explicitly request it before proceeding"
            ]
        },
        {
            "id": "phase-0a-assumption-check",
            "title": "Phase 0a: Assumption Verification Checkpoint",
            "prompt": "**ASSUMPTION CHECK** - Before proceeding, verify key assumptions to prevent bias.\n\n**VERIFY**:\n1. **Data State**: Confirm variable types and null handling\n2. **API/Library**: Check documentation for actual vs assumed behavior\n3. **Environment**: Verify bug exists in clean environment\n4. **Recent Changes**: Review last 5 commits for relevance\n\n**OUTPUT**: List verified assumptions with evidence sources.",
            "agentRole": "You are a skeptical analyst who challenges every assumption. Question everything that hasn't been explicitly verified.",
            "guidance": [
                "Use analysis tools to verify, don't assume",
                "Document each assumption with its verification method",
                "Flag any unverifiable assumptions for tracking",
                "CHECK API DOCS: Never assume function behavior from names - verify actual documentation",
                "VERIFY DATA TYPES: Use debugger or logs to confirm actual runtime types and values",
                "TEST ENVIRONMENT: Reproduce in minimal environment to rule out configuration issues"
            ]
        },
        {
            "id": "phase-0b-reproducibility-loop",
            "type": "loop",
            "title": "Phase 0b: Reproducibility Verification Loop",
            "loop": {
                "type": "for",
                "count": 3,
                "maxIterations": 3,
                "iterationVar": "reproductionAttempt"
            },
            "body": [
                {
                    "id": "reproduce-bug",
                    "title": "Reproduction Attempt {{reproductionAttempt}}/3",
                    "prompt": "**REPRODUCTION ATTEMPT {{reproductionAttempt}}/3**\n\nExecute the provided reproduction steps:\n1. Follow exact steps from bug report\n2. Document outcome (Success/Failure)\n3. Note any variations in behavior\n4. Capture error messages/stack traces\n\n**Update context:**\n- Set `reproductionResults[{{reproductionAttempt - 1}}]` = true/false\n- If failed, document why\n- Track any intermittent patterns",
                    "agentRole": "You are systematically verifying bug reproducibility to ensure solid investigation foundation.",
                    "guidance": [
                        "Execute exactly as specified",
                        "Document any deviations",
                        "Capture all error details"
                    ],
                    "requireConfirmation": false
                }
            ],
            "requireConfirmation": false
        },
        {
            "id": "phase-0c-reproducibility-assessment",
            "title": "Phase 0c: Reproducibility Assessment",
            "prompt": "**ASSESS REPRODUCIBILITY**\n\nBased on 3 reproduction attempts:\n- **Success Rate**: Calculate percentage\n- **Pattern Analysis**: Identify any intermittent patterns\n- **Minimal Reproduction**: Create simplified test case if needed\n\n**DECISION:**\n- If 100% reproducible: Proceed to Phase 1\n- If intermittent: Apply stress techniques and document patterns\n- If 0% reproducible: Request more information from user\n\n**Set `isReproducible` = true/false based on assessment**",
            "agentRole": "You are assessing reproduction results to determine investigation viability.",
            "guidance": [
                "100% reproduction is ideal but not always required",
                "Document intermittent patterns for investigation",
                "Create minimal test case for complex scenarios"
            ],
            "validationCriteria": [
                {
                    "type": "contains",
                    "value": "reproducib",
                    "message": "Must make reproducibility determination"
                }
            ],
            "hasValidation": true,
            "runCondition": {
                "var": "reproductionAttempt",
                "equals": 3
            }
        },
        {
            "id": "phase-1-streamlined-analysis",
            "runCondition": {
                "var": "bugComplexity",
                "equals": "simple"
            },
            "title": "Phase 1: Streamlined Analysis (Simple Bugs)",
            "prompt": "**STREAMLINED CODEBASE INVESTIGATION** - For simple bugs, I will perform focused analysis of the core issue.\n\n**STEP 1: Direct Component Analysis**\nI will examine the specific component involved:\n- **Primary Function/Method**: Direct analysis of the failing code\n- **Input/Output Analysis**: What data enters and exits the component\n- **Logic Flow**: Step-by-step execution path\n- **Error Point**: Exact location where failure occurs\n\n**STEP 2: Immediate Context Review**\n- **Recent Changes**: Git commits affecting this specific component\n- **Related Tests**: Existing test coverage for this functionality\n- **Dependencies**: Direct dependencies that could affect this component\n\n**STEP 3: Quick Hypothesis Formation**\nI will generate 1-3 focused hypotheses based on:\n- **Obvious Error Patterns**: Common failure modes for this type of component\n- **Change Impact**: How recent modifications could cause this issue\n- **Input Validation**: Whether invalid inputs are causing the failure\n\n**OUTPUTS**: Focused understanding of the simple bug with 1-3 targeted hypotheses ready for validation.",
            "agentRole": "You are an experienced debugging specialist who excels at quickly identifying and resolving straightforward technical issues. Your strength lies in pattern recognition and efficient root cause analysis for simple bugs. You focus on the most likely causes while avoiding over-analysis.",
            "guidance": [
                "FOCUSED ANALYSIS: Concentrate on the specific failing component, avoid deep architectural analysis",
                "PATTERN RECOGNITION: Use experience to identify common failure modes quickly",
                "EFFICIENT HYPOTHESIS: Generate 1-3 focused hypotheses, not exhaustive possibilities",
                "DIRECT APPROACH: Skip complex dependency analysis unless directly relevant"
            ]
        },
        {
            "id": "phase-1-comprehensive-analysis",
            "runCondition": {
                "or": [
                    {
                        "var": "bugComplexity",
                        "equals": "standard"
                    },
                    {
                        "var": "bugComplexity",
                        "equals": "complex"
                    }
                ]
            },
            "title": "Phase 1: Deep Codebase Analysis (Standard/Complex Bugs)",
            "prompt": "**SYSTEMATIC CODEBASE INVESTIGATION** - I will now perform comprehensive analysis of the relevant codebase components.\n\n**STEP 1: Affected Component Identification**\nBased on the bug report, I will identify and analyze:\n- **Primary Components**: Classes, functions, modules directly involved\n- **Dependency Chain**: Related components that could influence the bug\n- **Data Flow**: How data moves through the affected systems\n- **Error Propagation Paths**: Where and how errors can originate and propagate\n\n**STEP 2: Code Structure Analysis**\nFor each relevant component, I will examine:\n- **Implementation Logic**: Step-by-step code execution flow\n- **State Management**: How state is created, modified, and shared\n- **Error Handling**: Existing error handling mechanisms\n- **External Dependencies**: Third-party libraries, APIs, database interactions\n- **Concurrency Patterns**: Threading, async operations, shared resources\n\n**STEP 3: Historical Context Review**\nI will analyze:\n- **Recent Changes**: Git history around the affected components\n- **Test Coverage**: Existing tests and their coverage of the bug area\n- **Known Issues**: TODO comments, FIXME notes, or similar patterns\n\n**STEP 4: Recursive Dependency Dive**\nFor key components, analyze dependencies and internals recursively to uncover hidden issues.\n\n**OUTPUTS**: Comprehensive understanding of the codebase architecture and potential failure points.",
            "agentRole": "You are a principal software architect and code analysis expert specializing in systematic codebase investigation. Your strength lies in quickly understanding complex system architectures, identifying failure points, and tracing execution flows. You excel at connecting code patterns to potential runtime behaviors.",
            "guidance": [
                "SYSTEMATIC COVERAGE: Analyze all relevant components, not just the obvious ones",
                "EXECUTION FLOW FOCUS: Trace the actual code execution path that leads to the bug",
                "STATE ANALYSIS: Pay special attention to state management and mutation patterns",
                "DEPENDENCY MAPPING: Understand how external dependencies could contribute to the issue"
            ]
        },
        {
            "id": "phase-1a-binary-search",
            "title": "Phase 1a: Binary Search Isolation",
            "runCondition": {
                "or": [
                    {"var": "bugType", "equals": "regression"},
                    {"var": "searchSpace", "equals": "large"}
                ]
            },
            "prompt": "**BINARY SEARCH** - Apply divide-and-conquer:\n\n1. Identify GOOD state (working) and BAD state (broken)\n2. Find midpoint in history/code/data\n3. Test midpoint state\n4. Narrow to relevant half\n5. Document reduced search space\n\n**OUTPUT**: Narrowed location with evidence.",
            "agentRole": "You are a systematic investigator using algorithmic search to efficiently isolate issues.",
            "guidance": [
                "VERSION CONTROL: Use 'git bisect' or equivalent for commit history searches",
                "DATA PIPELINE: Test data at pipeline midpoints to isolate transformation issues",
                "TIME WINDOWS: For time-based issues, binary search through timestamps",
                "DOCUMENT BOUNDARIES: Clearly record each tested boundary and result",
                "EFFICIENCY: Each test should eliminate ~50% of remaining search space"
            ]
        },
        {
            "id": "phase-1b-test-reduction",
            "title": "Phase 1b: Test Case Minimization",
            "runCondition": {
                "var": "bugSource",
                "equals": "failing_test"
            },
            "prompt": "**TEST REDUCTION** - Simplify failing test:\n\n1. Inline called methods into test\n2. Add earlier assertion to fail sooner\n3. Remove code after new failure point\n4. Repeat until minimal\n\n**OUTPUT**: Minimal failing test case.",
            "agentRole": "You are a surgical debugger who strips away layers to reveal core issues.",
            "guidance": [
                "PRESERVE FAILURE: Each reduction must maintain the original failure mode",
                "INLINE AGGRESSIVELY: Replace method calls with their actual implementation",
                "FAIL EARLY: Move assertions up to find earliest deviation from expected state",
                "REMOVE RUTHLESSLY: Delete all code that doesn't contribute to the failure",
                "CLARITY GOAL: Final test should make the bug obvious to any reader"
            ]
        },
        {
            "id": "phase-2a-hypothesis-development",
            "title": "Phase 2a: Hypothesis Development & Prioritization",
            "prompt": "**HYPOTHESIS GENERATION** - Based on codebase analysis, formulate testable hypotheses about the bug's root cause.\n\n**STEP 1: Evidence-Based Hypothesis Development**\nCreate maximum 5 prioritized hypotheses. Each includes:\n- **Root Cause Theory**: Specific technical explanation\n- **Supporting Evidence**: Code patterns/logic flows supporting this theory\n- **Failure Mechanism**: Exact sequence leading to observed bug\n- **Testability Score**: Quantified assessment (1-10) of validation ease\n- **Evidence Strength Score**: Quantified assessment (1-10) based on code findings\n\n**STEP 2: Hypothesis Prioritization Matrix**\nRank hypotheses using weighted scoring:\n- **Evidence Strength** (40%): Code analysis support for theory\n- **Testability** (35%): Validation ease with debugging instruments\n- **Impact Scope** (25%): How well this explains all symptoms\n\n**CRITICAL RULE**: All hypotheses must be based on concrete evidence from code analysis.\n\n**OUTPUTS**: Maximum 5 hypotheses with quantified scoring, ranked by priority.",
            "agentRole": "You are a senior software detective and root cause analysis expert with deep expertise in systematic hypothesis formation. Your strength lies in connecting code evidence to potential failure mechanisms and creating testable theories. You excel at logical reasoning and evidence-based deduction. You must maintain rigorous quantitative standards and reject any hypothesis not grounded in concrete code evidence.",
            "guidance": [
                "EVIDENCE-BASED ONLY: Every hypothesis must be grounded in concrete code analysis findings with quantified evidence scores",
                "HYPOTHESIS LIMITS: Generate maximum 5 hypotheses to prevent analysis paralysis",
                "QUANTIFIED SCORING: Use 1-10 scales for evidence strength and testability with clear criteria"
            ],
            "validationCriteria": [
                {
                    "type": "contains",
                    "value": "Evidence Strength Score",
                    "message": "Must include quantified evidence strength scoring (1-10) for each hypothesis"
                },
                {
                    "type": "contains",
                    "value": "Testability Score",
                    "message": "Must include quantified testability scoring (1-10) for each hypothesis"
                }
            ],
            "hasValidation": true
        },
        {
            "id": "phase-2b-hypothesis-validation-strategy",
            "title": "Phase 2b: Hypothesis Validation Strategy & Documentation",
            "prompt": "**HYPOTHESIS VALIDATION PLANNING** - For the top 3 hypotheses, create validation strategies and documentation.\n\n**STEP 1: Hypothesis Validation Strategy**\nFor top 3 hypotheses, define:\n- **Required Evidence**: Specific evidence to confirm/refute hypothesis\n- **Debugging Approach**: Instrumentation/tests providing evidence\n- **Success Criteria**: Results proving hypothesis correct\n- **Confidence Threshold**: Minimum evidence quality needed\n\n**STEP 2: Hypothesis Documentation**\nCreate structured registry:\n- **Hypothesis ID**: H1, H2, H3 for tracking\n- **Status**: Active, Refuted, Confirmed\n- **Evidence Log**: Supporting and contradicting evidence\n- **Validation Plan**: Specific testing approach\n\n**STEP 3: Coverage Check**\nEnsure hypotheses cover diverse categories (logic, state, dependencies) with deep analysis.\n\n**OUTPUTS**: Top 3 hypotheses selected for validation with structured documentation and validation plans.",
            "agentRole": "You are a systematic testing strategist and documentation expert. Your strength lies in creating clear validation plans and maintaining rigorous documentation standards for hypothesis tracking and evidence collection.",
            "guidance": [
                "STRUCTURED DOCUMENTATION: Create formal hypothesis registry with tracking IDs and status",
                "VALIDATION RIGOR: Only proceed with top 3 hypotheses that meet minimum evidence thresholds",
                "COMPREHENSIVE PLANNING: Each hypothesis must have clear validation approach and success criteria"
            ],
            "validationCriteria": [
                {
                    "type": "contains",
                    "value": "Hypothesis ID",
                    "message": "Must assign tracking IDs (H1, H2, H3) to each hypothesis"
                },
                {
                    "type": "regex",
                    "pattern": "H[1-3]",
                    "message": "Must use proper hypothesis ID format (H1, H2, H3)"
                }
            ],
            "hasValidation": true
        },
        {
            "id": "phase-2c-prepare-validation",
            "title": "Phase 2c: Prepare Hypothesis Validation",
            "prompt": "**PREPARE VALIDATION ARRAY** - Extract the top 3 hypotheses for systematic validation.\n\n**Create `hypothesesToValidate` array with:**\n```json\n[\n  {\n    \"id\": \"H1\",\n    \"description\": \"[Hypothesis description]\",\n    \"evidenceStrength\": [score],\n    \"testability\": [score],\n    \"validationPlan\": \"[Specific testing approach]\"\n  },\n  // ... H2, H3\n]\n```\n\n**Set context variables:**\n- `hypothesesToValidate`: Array of top 3 hypotheses\n- `currentConfidence`: 0 (will be updated during validation)\n- `validationIterations`: 0 (tracks validation cycles)",
            "agentRole": "You are preparing the systematic validation process by structuring hypotheses for iteration.",
            "guidance": [
                "Extract only the top 3 hypotheses from Phase 2b",
                "Ensure each has complete validation information",
                "Initialize tracking variables for the validation loop"
            ],
            "requireConfirmation": false
        },
        {
            "id": "phase-3-4-5-validation-loop",
            "type": "loop",
            "title": "Hypothesis Validation Loop (Phases 3-4-5)",
            "loop": {
                "type": "forEach",
                "items": "hypothesesToValidate",
                "itemVar": "currentHypothesis",
                "indexVar": "hypothesisIndex",
                "maxIterations": 5
            },
            "body": [
                {
                    "id": "loop-phase-3-instrumentation",
                    "title": "Phase 3: Debug Instrumentation for {{currentHypothesis.id}}",
                    "prompt": "**DEBUGGING INSTRUMENTATION for {{currentHypothesis.id}}**\n\n**Hypothesis**: {{currentHypothesis.description}}\n**Validation Plan**: {{currentHypothesis.validationPlan}}\n\n**IMPLEMENT INSTRUMENTATION:**\n1. **Strategy**: Choose based on hypothesis needs (logging, debug prints, test mods)\n2. **Coverage**: Instrument all paths related to {{currentHypothesis.id}}\n3. **Evidence Points**: Focus on gathering evidence that will confirm/refute this specific hypothesis\n\n**LOG OPTIMIZATION:**\n- Use '{{currentHypothesis.id}}_DEBUG:' prefix for all logs\n- Implement deduplication for high-frequency events\n- Group related operations within 50-100ms windows\n\n**OUTPUT**: Instrumented code ready to validate {{currentHypothesis.id}}",
                    "agentRole": "You are instrumenting code specifically to validate hypothesis {{currentHypothesis.id}}. Focus on targeted evidence collection.",
                    "guidance": [
                        "This is hypothesis {{hypothesisIndex + 1}} of {{hypothesesToValidate.length}}",
                        "Tailor instrumentation to the specific hypothesis",
                        "Ensure non-intrusive implementation"
                    ],
                    "requireConfirmation": false
                },
                {
                    "id": "loop-phase-4-evidence",
                    "title": "Phase 4: Evidence Collection for {{currentHypothesis.id}}",
                    "prompt": "**EVIDENCE COLLECTION for {{currentHypothesis.id}}**\n\n**Execute instrumented code and collect evidence:**\n1. Run the instrumented test/reproduction\n2. Collect all {{currentHypothesis.id}}_DEBUG logs\n3. Analyze results against validation criteria\n4. Document evidence quality and relevance\n\n**EVIDENCE ASSESSMENT:**\n- Does evidence support {{currentHypothesis.id}}? (Yes/No/Partial)\n- Evidence quality score (1-10)\n- Contradicting evidence found?\n- Additional evidence needed?\n\n**If log volume >500 lines, create sub-analysis prompt.**\n\n**OUTPUT**: Evidence assessment for {{currentHypothesis.id}} with quality scoring",
                    "agentRole": "You are collecting and analyzing evidence specifically for hypothesis {{currentHypothesis.id}}.",
                    "guidance": [
                        "Focus on evidence directly related to this hypothesis",
                        "Be objective in assessment - negative evidence is valuable",
                        "Track evidence quality quantitatively"
                    ],
                    "requireConfirmation": false
                },
                {
                    "id": "loop-phase-5-synthesis",
                    "title": "Phase 5: Evidence Synthesis for {{currentHypothesis.id}}",
                    "prompt": "**EVIDENCE SYNTHESIS for {{currentHypothesis.id}}**\n\n**Synthesize findings:**\n1. **Evidence Summary**: What did we learn about {{currentHypothesis.id}}?\n2. **Confidence Update**: Based on evidence, rate confidence this is the root cause (0-10)\n3. **Status Update**: Mark hypothesis as Confirmed/Refuted/Needs-More-Evidence\n\n**If {{currentHypothesis.id}} is confirmed with high confidence (>8.0):**\n- Set `rootCauseFound` = true\n- Set `rootCauseHypothesis` = {{currentHypothesis.id}}\n- Update `currentConfidence` with confidence score\n\n**If all hypotheses validated but confidence <9.0:**\n- Consider additional investigation needs\n- Document what evidence is still missing",
                    "agentRole": "You are synthesizing evidence to determine if {{currentHypothesis.id}} is the root cause.",
                    "guidance": [
                        "Update hypothesis status based on evidence",
                        "Track overall investigation confidence",
                        "Be ready to exit loop if root cause found with high confidence"
                    ],
                    "requireConfirmation": false
                }
            ],
            "runCondition": {
                "and": [
                    { "var": "rootCauseFound", "not_equals": true },
                    { "var": "validationIterations", "lt": 3 }
                ]
            },
            "requireConfirmation": false
        },
        {
            "id": "phase-3a-observability-setup",
            "title": "Phase 3a: Distributed System Observability",
            "runCondition": {
                "var": "isDistributed",
                "equals": true
            },
            "prompt": "**OBSERVABILITY** - Set up three-pillar strategy:\n\n**METRICS**: Identify key indicators (latency, errors)\n**TRACES**: Enable request path tracking\n**LOGS**: Ensure correlation IDs present\n\n**OUTPUT**: Observability checklist completed.",
            "agentRole": "You are a distributed systems expert who thinks in terms of emergent behaviors and system-wide patterns.",
            "guidance": [
                "METRICS SELECTION: Focus on RED metrics (Rate, Errors, Duration) for each service",
                "TRACE COVERAGE: Ensure spans cover all service boundaries and key operations",
                "CORRELATION IDS: Verify IDs propagate through entire request lifecycle",
                "AGGREGATION READY: Set up centralized collection for cross-service analysis",
                "BASELINE ESTABLISHMENT: Capture normal behavior metrics for comparison"
            ]
        },
        {
            "id": "phase-4a-distributed-evidence",
            "title": "Phase 4a: Multi-Service Evidence Collection",
            "runCondition": {
                "var": "isDistributed",
                "equals": true
            },
            "prompt": "**DISTRIBUTED ANALYSIS**:\n\n1. Check METRICS for anomalies\n2. Follow TRACES for request path\n3. Correlate LOGS across services\n4. Identify cascade points\n\n**OUTPUT**: Service interaction map with failure points.",
            "agentRole": "You are a systems detective who can trace failures across service boundaries.",
            "guidance": [
                "ANOMALY DETECTION: Look for deviations in latency, error rates, or traffic patterns",
                "TRACE ANALYSIS: Follow request ID through all services to find failure point",
                "LOG CORRELATION: Use timestamp windows and correlation IDs to link events",
                "CASCADE IDENTIFICATION: Look for timeout chains or error propagation patterns",
                "VISUAL MAPPING: Create service dependency diagram with failure annotations"
            ]
        },
        {
            "id": "phase-4b-cognitive-reset",
            "title": "Phase 4b: Cognitive Reset & Progress Review",
            "runCondition": {
                "var": "validationIterations",
                "gte": 2
            },
            "prompt": "**COGNITIVE RESET** - Step back and review:\n\n1. Summarize findings so far\n2. List eliminated possibilities\n3. Identify investigation blind spots\n4. Reformulate approach if needed\n\n**DECIDE**: Continue current path or pivot strategy?",
            "agentRole": "You are a strategic advisor who helps maintain perspective during complex investigations.",
            "guidance": [
                "PROGRESS SUMMARY: Write concise bullet points of key findings and eliminations",
                "BLIND SPOT CHECK: What areas haven't been investigated? What assumptions remain?",
                "PATTERN RECOGNITION: Look for investigation loops or repeated dead ends",
                "STRATEGY EVALUATION: Is current approach yielding diminishing returns?",
                "PIVOT CRITERIA: Consider new approach if last 3 iterations provided no new insights"
            ]
        },
        {
            "id": "phase-5a-final-confidence",
            "title": "Phase 5a: Final Confidence Assessment",
            "prompt": "**FINAL CONFIDENCE ASSESSMENT** - Evaluate the investigation results.\n\n**If root cause found (rootCauseFound = true):**\n- Review all evidence for {{rootCauseHypothesis}}\n- Perform adversarial challenge\n- Calculate final confidence score\n\n**If no high-confidence root cause:**\n- Document what was learned\n- Identify remaining unknowns\n- Recommend next investigation steps\n\n**CONFIDENCE CALCULATION:**\n- Evidence Quality (1-10)\n- Explanation Completeness (1-10)\n- Alternative Likelihood (1-10, inverted)\n- Final = (Quality Ã— 0.4) + (Completeness Ã— 0.4) + (Alternative Ã— 0.2)\n\n**OUTPUT**: Final confidence assessment with recommendations",
            "agentRole": "You are making the final determination about the root cause with rigorous confidence assessment.",
            "guidance": [
                "Be honest about confidence levels",
                "Document all remaining uncertainties",
                "Provide clear next steps if confidence is low"
            ],
            "validationCriteria": [
                {
                    "type": "regex",
                    "pattern": "Final.*=.*[0-9\\.]+",
                    "message": "Must calculate final confidence score"
                }
            ],
            "hasValidation": true
        },
        {
            "id": "phase-2c-hypothesis-assumptions",
            "title": "Phase 2c: Hypothesis Assumption Audit",
            "prompt": "**AUDIT** each hypothesis for hidden assumptions:\n\n**FOR EACH HYPOTHESIS**:\n- List implicit assumptions\n- Rate assumption confidence (1-10)\n- Identify verification approach\n\n**REJECT** hypotheses built on unverified assumptions.",
            "agentRole": "You are a rigorous scientist who rejects any hypothesis not grounded in verified facts.",
            "guidance": [
                "EXPLICIT LISTING: Write out every assumption, no matter how obvious it seems",
                "CONFIDENCE SCORING: Rate 1-10 based on evidence quality, not intuition",
                "VERIFICATION PLAN: For each assumption, specify how it can be tested",
                "REJECTION CRITERIA: Any assumption with confidence <7 requires verification",
                "DOCUMENT RATIONALE: Explain why each assumption is accepted or needs testing"
            ],
            "validationCriteria": [
                {
                    "type": "contains",
                    "value": "Assumption confidence",
                    "message": "Must rate assumption confidence for each hypothesis"
                }
            ],
            "hasValidation": true
        },
        {
            "id": "phase-6-diagnostic-writeup",
            "title": "Phase 6: Comprehensive Diagnostic Writeup",
            "prompt": "**FINAL DIAGNOSTIC DOCUMENTATION** - I will create comprehensive writeup enabling effective bug fixing and knowledge transfer.\n\n**STEP 1: Executive Summary**\n- **Bug Summary**: Concise description of issue and impact\n- **Root Cause**: Clear, non-technical explanation of what is happening\n- **Confidence Level**: Final confidence assessment with calculation methodology\n- **Scope**: What systems, users, or scenarios are affected\n\n**STEP 2: Technical Deep Dive**\n- **Root Cause Analysis**: Detailed technical explanation of failure mechanism\n- **Code Component Analysis**: Specific files, functions, and lines with exact locations\n- **Execution Flow**: Step-by-step sequence of events leading to bug\n- **State Analysis**: How system state contributes to failure\n\n**STEP 3: Investigation Methodology**\n- **Investigation Timeline**: Chronological summary with phase time investments\n- **Hypothesis Evolution**: Complete record of hypotheses (H1-H5) with status changes\n- **Evidence Assessment**: Rating and reliability of evidence sources with key citations\n\n**STEP 4: Knowledge Transfer & Action Plan**\n- **Skill Requirements**: Technical expertise needed for understanding and fixing\n- **Prevention & Review**: Specific measures and code review checklist items\n- **Action Items**: Immediate mitigation steps and permanent fix areas with timelines\n- **Testing Strategy**: Comprehensive verification approach for fixes\n\n**DELIVERABLE**: Enterprise-grade diagnostic report enabling confident bug fixing, knowledge transfer, and organizational learning.",
            "agentRole": "You are a senior technical writer and diagnostic documentation specialist with expertise in creating comprehensive, actionable bug reports for enterprise environments. Your strength lies in translating complex technical investigations into clear, structured documentation that enables effective problem resolution, knowledge transfer, and organizational learning. You excel at creating reports that serve immediate fixing needs, long-term system improvement, and team collaboration.",
            "guidance": [
                "ENTERPRISE FOCUS: Write for multiple stakeholders including developers, managers, and future team members",
                "KNOWLEDGE TRANSFER: Include methodology and reasoning, not just conclusions",
                "COLLABORATIVE DESIGN: Structure content for peer review and team coordination",
                "COMPREHENSIVE COVERAGE: Include all information needed for resolution and prevention",
                "ACTIONABLE DOCUMENTATION: Provide specific, concrete next steps with clear ownership"
            ]
        }
    ]
}